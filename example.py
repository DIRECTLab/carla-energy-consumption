#!/usr/bin/env python

# Adapted from tutorial.py (Copyright (c) 2019 Computer Vision Center (CVC) at the Universitat Autonoma de
# Barcelona (UAB).)
#
# This work is licensed under the terms of the MIT license.
# For a copy, see <https://opensource.org/licenses/MIT>.

import glob
import os
import sys

try:
    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (
        sys.version_info.major,
        sys.version_info.minor,
        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])
except IndexError:
    pass

import carla

import random
import time

from time_tracker import TimeTracker
from distance_tracker import DistanceTracker
from energy_tracker import EnergyTracker


def main():
    actor_list = []

    # In this tutorial script, we are going to add a vehicle to the simulation
    # and let it drive in autopilot. We will also create a camera attached to
    # that vehicle, and save all the images generated by the camera to disk.

    camera = None
    client = None

    try:
        # First of all, we need to create the client that will send the requests
        # to the simulator. Here we'll assume the simulator is accepting
        # requests in the localhost at port 2000.
        client = carla.Client('127.0.0.1', 2000)
        client.set_timeout(10.0)

        # Once we have a client we can retrieve the world that is currently
        # running.
        world = client.get_world()

        # world = client.load_world('Town04')
        world = client.load_world('Town10HD')

        # Set traffic manager to normal speed (instead of default 70%)
        traffic_manager = client.get_trafficmanager()
        traffic_manager.global_percentage_speed_difference(0)

        # The world contains the list blueprints that we can use for adding new
        # actors into the simulation.
        blueprint_library = world.get_blueprint_library()

        # Now let's filter all the blueprints of type 'vehicle' and choose one
        # at random.
        # bp = random.choice(blueprint_library.filter('vehicle.bmw.grandtourer'))
        bp = random.choice(blueprint_library.filter('vehicle.tesla.model3'))

        # A blueprint contains the list of attributes that define a vehicle's
        # instance, we can read them and modify some of them. For instance,
        # let's randomize its color.
        # if bp.has_attribute('color'):
        #     recommended_colors = bp.get_attribute('color').recommended_values
        #     print(f"Recommended colors: {recommended_colors}")
        #     color = random.choice(recommended_colors)
        #     bp.set_attribute('color', color)
        bp.set_attribute('color', '204,255,11') # Lime green to make it visible

        bp.set_attribute('role_name', 'hero')
        traffic_manager.set_hybrid_physics_mode(True)
        traffic_manager.set_respawn_dormant_vehicles(True)

        # Now we need to give an initial transform to the vehicle. We choose a
        # random transform from the list of recommended spawn points of the map.
        transform = random.choice(world.get_map().get_spawn_points())

        # So let's tell the world to spawn the vehicle.
        vehicle = world.spawn_actor(bp, transform)

        # It is important to note that the actors we create won't be destroyed
        # unless we call their "destroy" function. If we fail to call "destroy"
        # they will stay in the simulation even after we quit the Python script.
        # For that reason, we are storing all the actors we create so we can
        # destroy them afterwards.
        actor_list.append(vehicle)
        print('created %s' % vehicle.type_id)

        physics_vehicle = vehicle.get_physics_control()
        mass = physics_vehicle.mass
        print(f"Mass: {mass} kg")
        # https://arxiv.org/pdf/1908.08920.pdf%5D pg17
        drag = 0.23
        frontal_area = 2.22

        # Let's put the vehicle to drive around.
        vehicle.set_autopilot(True)

        # # Let's add now a "depth" camera attached to the vehicle. Note that the
        # # transform we give here is now relative to the vehicle.
        # camera_bp = blueprint_library.find('sensor.camera.depth')
        # camera_transform = carla.Transform(carla.Location(x=1.5, z=2.4))
        # camera = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)
        # actor_list.append(camera)
        # print('created %s' % camera.type_id)

        # # Now we register the function that will be called each time the sensor
        # # receives an image. In this example we are saving the image to disk
        # # converting the pixels to gray-scale.
        # cc = carla.ColorConverter.LogarithmicDepth
        # camera.listen(lambda image: image.save_to_disk('_out/%06d.png' % image.frame, cc))

        # Oh wait, I don't like the location we gave to the vehicle, I'm going
        # to move it a bit forward.
        # location = vehicle.get_location()
        # location.x += 40
        # vehicle.set_location(location)
        # print('moved vehicle to %s' % location)

        # But the city now is probably quite empty, let's add a few more
        # vehicles.
        for _ in range(0, 50):
            bp = random.choice(blueprint_library.filter('vehicle'))

            for _ in range(5):  # Try spawning 5 times
                transform = random.choice(world.get_map().get_spawn_points())
                npc = world.try_spawn_actor(bp, transform)
                if npc is not None:
                    actor_list.append(npc)
                    npc.set_autopilot(True)
                    # print('created %s' % npc.type_id)
                    break
        print(f"Total number of vehicles: {len(actor_list)}")

        time_tracker = TimeTracker(vehicle)
        distance_tracker = DistanceTracker(vehicle)
        energy_tracker = EnergyTracker(vehicle, hvac=0, A_f=frontal_area, C_D=drag)

        # for t in range(50):
        while True:
            time.sleep(1)
            print(f"After {time_tracker.time:G} s:")
            print(f"\tDistance travelled: {distance_tracker.distance_travelled:G} m")
            m_per_s = distance_tracker.distance_travelled / time_tracker.time
            km_per_h = m_per_s * 60 * 60 / 1000
            mph = km_per_h / 1.60934
            print(f"\tAverage speed: {m_per_s:G} m/s ({km_per_h:G} km/h) ({mph:G} mph)")
            print(f"\tEnergy consumed: {energy_tracker.total_energy:G} kWh")
            kWh_per_m = energy_tracker.total_energy / distance_tracker.distance_travelled
            kWh_per_100km = kWh_per_m * 1000 * 100
            kWh_per_100mi = kWh_per_100km * 1.60934
            print(f"\tEnergy efficiency: {kWh_per_m:G} kWh/m ({kWh_per_100km:G} kWh / 100 km) ({kWh_per_100mi:G} kWh / 100 mi)")

    except KeyboardInterrupt:
        pass

    finally:

        print('destroying actors')
        if camera is not None:
            camera.destroy()
        if client is not None:
            client.apply_batch([carla.command.DestroyActor(x) for x in actor_list])
        print('done.')


if __name__ == '__main__':

    main()
